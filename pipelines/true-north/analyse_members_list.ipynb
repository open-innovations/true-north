{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')\n",
    "from pipelines.util import *\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(WDIR, 'true-north/true_north_clean.csv'))\n",
    "data.drop(columns='associated Company Domain (Contact Level)', inplace=True)\n",
    "# data[data['Industry'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe with the same columns as `data`\n",
    "summary = pd.DataFrame(columns=data.columns.to_list())\n",
    "summary.loc['count'] = data.count()\n",
    "mode = data.mode().head(1)\n",
    "mode.reset_index(drop=True, inplace=True)\n",
    "mode.rename(index={0: 'top'}, inplace=True)\n",
    "summary = pd.concat([summary, mode])\n",
    "freq = data.apply(lambda x: x.value_counts(dropna=True).max())\n",
    "summary.loc['freq'] = freq\n",
    "\n",
    "unique = data.nunique(dropna=True)\n",
    "summary.loc['unique'] = unique\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = data.describe()\n",
    "summary.loc['top_percent_of_count'] = (summary.loc['freq'] * 100 / summary.loc['count']).astype(float).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_names = pd.Series(data['Company Name'].sort_values())\n",
    "print(company_names.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is LLoyds banking group and lloyds bank plc - we're assuming these are different companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the month column to a datetime object\n",
    "data['month'] = pd.to_datetime(data['Create Date'])\n",
    "\n",
    "#convert the item to a formatted value in yyyy-mm format.\n",
    "data['month_formatted'] = data['month'].apply(datetime.strftime, format='%Y-%m').sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the number of members and calculate the number that joined each month.\n",
    "monthly_members = pd.DataFrame(data['month_formatted'].value_counts(ascending=False)).reset_index()\n",
    "monthly_members['start_of_month'] = monthly_members['month_formatted'].astype(str) + '-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_orgs = data.drop_duplicates(subset='Company Name', keep='last')\n",
    "monthly_orgs = pd.DataFrame(monthly_orgs['month_formatted'].value_counts(ascending=False)).reset_index()\n",
    "monthly_orgs['start_of_month'] = monthly_orgs['month_formatted'].astype(str) + '-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_date(data):\n",
    "    # make a unix timestamp column\n",
    "    data['timestamp'] = pd.to_datetime(data['month_formatted'], format='%Y-%m').astype(int) / 10**9\n",
    "    # make a decimal date and round to 2dp.\n",
    "    data['year'] = data['timestamp'].div((86400*365.25)).add(1970).round(2)\n",
    "    # drop the timestamp column\n",
    "    data.drop(columns='timestamp', inplace=True) \n",
    "    # set year and formatted month as the index so they aren't included in the cumsum.\n",
    "    data.set_index(['year', 'month_formatted', 'start_of_month'], inplace=True, append=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cumsum(data, count_name):\n",
    "    # order by date, then do the cumsum. reset the index, drop the original index column as not needed\n",
    "    data = pd.DataFrame(data.sort_index(level=2).cumsum(skipna=True).reset_index().drop(columns='level_0'))\n",
    "    data.rename(columns={'count': f'{count_name}'}, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply above functions to data\n",
    "cs_monthly_members = calculate_cumsum(decimal_date(monthly_members), count_name='individuals')\n",
    "cs_monthly_orgs = calculate_cumsum(decimal_date(monthly_orgs), count_name='orgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged the two dataframes\n",
    "cs_merged = cs_monthly_members.merge(cs_monthly_orgs, how='inner', on=['year', 'month_formatted', 'start_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "cs_merged.to_csv(os.path.join(SRC_DIR,'overview/membership/_data/cumsum.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a bar chart for locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = data.copy()\n",
    "split_locs = locations['location'].str.split(';').apply(pd.Series, 1).stack()\n",
    "split_locs.index = split_locs.index.droplevel(-1)\n",
    "split_locs.name = 'location'\n",
    "del locations['location']\n",
    "locations = locations.join(split_locs)\n",
    "locations['location'] = locations['location'].str.lstrip()\n",
    "top_locations = locations['location'].value_counts().reset_index().head(5)\n",
    "top_locations.to_csv(os.path.join(SRC_DIR, 'overview/membership/_data/top_locations.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating some summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_members = len(data.index)\n",
    "\n",
    "total_companies = summary.loc['unique', 'Company Name']\n",
    "\n",
    "top_company_size = summary.loc['top', 'company_size']\n",
    "\n",
    "top_company_size_pct = summary.loc['top_percent_of_count', 'company_size']\n",
    "\n",
    "# top_industry = summary.loc['top', 'Industry']\n",
    "top_industry = ''\n",
    "top_industry_pct = 0\n",
    "# top_industry_pct = summary.loc['top_percent_of_count', 'Industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['City']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequency in the sector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    # Convert to lowercase and remove non-alphanumeric characters (keeping spaces)\n",
    "    try:\n",
    "        s = s.lower()\n",
    "    except:\n",
    "        print(f\"'{s}' is not a stirng type. Converting to string\\n\")\n",
    "        return str(s)\n",
    "    s = re.sub(r'[^a-z0-9\\s]', '', s)\n",
    "    return s\n",
    "data['normalized_sector'] = data['sector'].apply(normalize_string).str.split(';')\n",
    " \n",
    "# Flatten the list and further split by spaces to handle multi-word strings\n",
    "all_words = [word for sublist in data['normalized_sector'] for item in sublist for word in item.split()]\n",
    " \n",
    "# Count the occurrences of each word\n",
    "word_counts = Counter(all_words)\n",
    " \n",
    "# Find the most common word\n",
    "most_common_words = word_counts.most_common(10)\n",
    "least_common_words = word_counts.most_common()\n",
    "\n",
    "banned_words = ['and', 'or', 'of', 'it', 'the', 'for', 'with', 'we', 'nan', 'please', 'specify']\n",
    "# print(\"The 10 most common words, not including 'and' are:\") \n",
    "# for word, count in most_common_words:\n",
    "#     if word == banned_words:\n",
    "#         continue\n",
    "#     print(f\"'{word}' with {count} occurences\")\n",
    "\n",
    "print(\"The most common words, with at least 2 occurences are:\")\n",
    "words = []\n",
    "counts = []\n",
    "for word, count in least_common_words:\n",
    "    if word in banned_words:\n",
    "        continue\n",
    "    if word == 'estate':\n",
    "        continue\n",
    "    if count >= 10:\n",
    "        if word == 'real':\n",
    "            words.append('real estate')\n",
    "        else:\n",
    "            words.append(word)\n",
    "        counts.append(count)\n",
    "        print(f\"'{word}' with {count} occurences\")\n",
    "\n",
    "sector_counts = pd.DataFrame(data={'name': words, 'count': counts}).set_index('name')\n",
    "# sector_counts['colour'] = round((sector_counts['count'] - min(sector_counts['count'])) / sector_counts['count'].max(), 3)\n",
    "sector_counts.to_csv(os.path.join(SRC_DIR, 'overview/membership/_data/sector_word_counts.csv'))\n",
    "# sector_strings = [item for sublist in data['sector'].str.split(';') for item in sublist]\n",
    "# string_counts = Counter(sector_strings)\n",
    "# print(string_counts.most_common())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advisory_council = 11\n",
    "\n",
    "if summary.loc['top', \"Are you currently a B Corp or in the process of becoming a B Corp?\"] == 'No':\n",
    "    b_corps_pct = round(100 - summary.loc['top_percent_of_count', \"Are you currently a B Corp or in the process of becoming a B Corp?\"], 1)\n",
    "else:\n",
    "    summary.loc['top_percent_of_count', \"Are you currently a B Corp or in the process of becoming a B Corp?\"]\n",
    "\n",
    "membership_increase = cs_merged['individuals'].pct_change().mul(100).iloc[-1].round(1)\n",
    "\n",
    "northern_stars = len(pd.read_csv(os.path.join(SRC_DIR, 'overview/northern-stars/_data/northern_stars.csv')))\n",
    "\n",
    "names = [\"Total members\", \n",
    "         \"Total companies\", \n",
    "         \"Membership increase\", \n",
    "         f\"Companies with {top_company_size} employees\", \n",
    "         \"Top industry\", \n",
    "         \"Geographic reach\", \n",
    "         \"Advisory council\", \n",
    "         \"Northern stars\", \n",
    "         \"B Corps\"]\n",
    "\n",
    "values = [total_members, \n",
    "          total_companies, \n",
    "          membership_increase, \n",
    "          top_company_size_pct, \n",
    "          top_industry_pct, \n",
    "          \"4\", \n",
    "          advisory_council, \n",
    "          northern_stars, \n",
    "          b_corps_pct]\n",
    "\n",
    "footnotes = [\"People\", \n",
    "             \"Unique companies\", \n",
    "             \"Since last month\", \n",
    "             \"Of members work in companies of this size\", \n",
    "             f\"Of members work in {top_industry}\", \n",
    "             \"placeholder\", \n",
    "             \"Members represent the network on the True North advisory council\", \n",
    "             \"Companies have been featured as Northern Stars\", \n",
    "             \"Of member's organisations are B Corps or are joining\"]\n",
    "\n",
    "posts = ['','','%','%','%','','','','%']\n",
    "\n",
    "urls = ['/overview/membership', '/overview/membership', '/overview/membership', '', '', '', 'https://www.brabners.com/insights/true-north/true-north-advisory-council-launches', '/overview/northern-stars', '/themes/sustainable-growth/b-corporations']\n",
    "dashboard = pd.DataFrame(data={'name':names, 'value': values, 'footnote': footnotes, 'post': posts, 'url': urls})\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard.to_csv(os.path.join(SRC_DIR, 'overview/membership/_data/true_north_members_list.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_updated('src/overview/membership/_data/updated.yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "true-north-n9oHZhgB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
