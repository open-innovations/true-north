{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some modules, and set up this notebook to read files correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')\n",
    "from pipelines.util import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data files into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(os.path.join(WDIR, 'true-north/OITrue North data June 2024[32].xlsx'))\n",
    "# additional_members = pd.read_excel(os.path.join(WDIR, 'true-north/true north_additional_members_list_19_06_24.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional_members['Create Date'] = '2024-06-20 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([hubspot_export, additional_members]).reset_index(drop=True)\n",
    "# data = hubspot_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dates should all start in May 2023 or later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Create Date'] = pd.to_datetime(data['Create Date'])\n",
    "start_date = pd.Timestamp('2023-05-01')\n",
    "data.loc[data['Create Date'] < start_date, 'Create Date'] = start_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a \"last_updated\" column which uses the 'last activity date' column if it exists, otherwise the create date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Name',\n",
       " 'Last Name',\n",
       " 'Create Date',\n",
       " 'Last Activity Date',\n",
       " 'How many people work in your organisation?',\n",
       " 'What sector(s) does your organisation operate in? [Other]',\n",
       " 'What sector(s) does your organisation operate in??',\n",
       " 'What sector(s) does your organisation operate in?',\n",
       " 'Where is your organisation based? Select all that apply',\n",
       " 'Where is your organisation based? Select all that apply [Other]',\n",
       " 'Where is your company based? ',\n",
       " 'Which theme of the True North report do you most identify with and could support activity around? (select all that apply)',\n",
       " 'Which theme of the True North report do you most identify with and could support activity around? ',\n",
       " 'Do you feel the True North report identified the key challenges and opportunities facing the region? ',\n",
       " 'Are you interested in attending future True North events? ',\n",
       " 'How would you like to be involved with the True North network (select all that apply)? [Other]',\n",
       " 'How would you like to be involved with the True North network (select all that apply)?',\n",
       " 'Are you currently a B Corp or in the process of becoming a B Corp?',\n",
       " 'Would you be interested in hearing more from Brabners about the B Corp process?',\n",
       " 'Company Name',\n",
       " 'City',\n",
       " 'Industry',\n",
       " 'associated Company Domain (Contact Level)',\n",
       " 'last_updated']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Currently have both create date (when the person filled the questionnaire for the first time) and the \"last_updated\"\n",
    "# date, which is the \"Last Activity Date\" iff it exists, otherwise it is the \"Create Date\"\n",
    "data['last_updated'] = data['Last Activity Date'].combine_first(data['Create Date'])\n",
    "data.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a list of all the columns we don't need, and then remove them (drop) from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Last Activity Date', 'Where is your company based? ']\n",
    "data.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following 4 code blocks this logic applies:\n",
    "- Make a list of columns that are the same question and need merging. \n",
    "- Merge them together with priority according to the order of the list. \n",
    "- If an entry exists, use that value. Otherwise, go to the next column.\n",
    "- Add this as a new, single column with a new title.\n",
    "- Remove the old columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['What sector(s) does your organisation operate in? [Other]', 'What sector(s) does your organisation operate in??', 'What sector(s) does your organisation operate in?']\n",
    "# cols are F,G,H\n",
    "# data['sector'] = data[cols[0]].combine_first(data[cols[1]]).combine_first(data[cols[2]])\n",
    "\n",
    "def combine_sectors(row):\n",
    "    if row[cols[2]] == 'Other - please specify':\n",
    "        return row[cols[0]]\n",
    "    elif pd.notnull(row[cols[1]]):\n",
    "        return row[cols[1]]\n",
    "    elif pd.notnull(row[cols[2]]):\n",
    "        return row[cols[2]]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "data['sector'] = data.apply(combine_sectors, axis=1)\n",
    "data.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Where is your organisation based? Select all that apply', 'Where is your organisation based? Select all that apply [Other]']\n",
    "data['location'] = data[cols[0]].combine_first(data[cols[1]])\n",
    "data.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Which theme of the True North report do you most identify with and could support activity around? (select all that apply)', \n",
    "        'Which theme of the True North report do you most identify with and could support activity around? ']\n",
    "data['Which theme of the True North report do you most identify with and could support activity around?'] = data[cols[0]].combine_first(data[cols[1]])\n",
    "data.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['How would you like to be involved with the True North network (select all that apply)? [Other]',\n",
    "        'How would you like to be involved with the True North network (select all that apply)?']\n",
    "data['How would you like to be involved with the True North network?'] = data[cols[0]].combine_first(data[cols[1]])\n",
    "data.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping the company sizes onto the standard ranges. Assuming there are no edge cases.\n",
    "\n",
    "One company had both 1-10 and 11-50 as a company range. We've opted for the 10-49 range based on probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '501 - 1,000', '11 - 50', '1,000+', '1 - 10', '51 - 100',\n",
       "       '101 - 250', '251 - 500', '1 - 10; 11 - 50'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['How many people work in your organisation?'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {\n",
    "    '1 - 10': '0-9', \n",
    "    '51 - 100': '50-249', \n",
    "    '11 - 50': '10-49', \n",
    "    '101 - 250': '50-249',\n",
    "    '251 - 500': '250+', \n",
    "    '501 - 1,000': '250+', \n",
    "    '1 - 10; 11 - 50': '10-49', \n",
    "    '51 - 200': '50-249',\n",
    "    '2 - 10': '0-9', \n",
    "    '501 - 1000': '250+', \n",
    "    '11 - 50 ': '10-49', \n",
    "    '1,000+': '1000+',\n",
    "    '104 - 250': '50-249', \n",
    "    '51-200': '50-249', \n",
    "    '101-250': '50-249', \n",
    "    '2 - 11': '0-9', \n",
    "    'Self-employed': 'Self-Employed', \n",
    "    'Self employed': 'Self-Employed',\n",
    "    'nan': ''\n",
    "    }\n",
    "\n",
    "data['company_size'] = data['How many people work in your organisation?'].replace(mapper)\n",
    "data.drop(columns='How many people work in your organisation?', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the new, cleaner categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '250+', '10-49', '1000+', '0-9', '50-249'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.company_size.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the values by last_updated date, with oldest at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by='last_updated', inplace=True, ascending=False)\n",
    "data.set_index('last_updated', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that some entries are likely to be from the same company. Currently these are:\n",
    "- TUBR LTD; gettubr.com\n",
    "- Sitehop; Sitehop.com\n",
    "\n",
    "We will manually correct these, using the row with the actual company name (not url) as prioirity, and filling blanks with any entries (if present) from the other row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_duplicate_companies(data, names):\n",
    "#     '''\n",
    "#         Names is a list of 2 company names to merge. \n",
    "#         First company name in the list is used as priority when merging.\n",
    "#         Function assumes only 2 duplicate entries. Can be adjusted in future if we need to account for n duplicates.\n",
    "#     '''\n",
    "#     # reset the index to access data by a numeric index\n",
    "#     data.reset_index(inplace=True)\n",
    "    \n",
    "#     # get the indices of the named rows\n",
    "#     index_a = data.index[data['Company Name'] == names[0]]\n",
    "#     index_b = data.index[data['Company Name'] == names[1]]\n",
    "\n",
    "#     # combine the rows\n",
    "#     combined_row = data.iloc[index_a].combine_first(data.iloc[index_b])\n",
    "\n",
    "#     # insert the row into the dataframe at index_a \n",
    "#     data.loc[index_a] = combined_row\n",
    "\n",
    "#     # drop index b as no longer needed, reset the index and drop the old one, set the index to \"last_updated\".\n",
    "#     data = data.drop(index_b).reset_index(drop=True).set_index('last_updated')\n",
    "\n",
    "#     print('Successfully merged rows and created the following row: \\n', data.loc[data['Company Name'] == names[0]].to_csv())\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find rows where there company name is duplicated, but not NA, and the first and last name of the contact are not duplicated.\n",
    "\n",
    "Get the names of these companies\n",
    "\n",
    "iterate through them\n",
    "\n",
    "find the rows that match this company name\n",
    "\n",
    "sort them by date descending\n",
    "\n",
    "remove the all rows from `data` apart from the most recent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = data[data['Company Name'].duplicated() & data['Company Name'].notna() & data['First Name'].duplicated() & data['Last Name'].duplicated()]['Company Name']\n",
    "# data = merge_duplicate_companies(data, ['TUBR', 'gettubr.com'])\n",
    "# data = merge_duplicate_companies(data, ['Sitehop', 'Sitehop'])\n",
    "names.values\n",
    "for name in names.values:\n",
    "    dupe_rows = data[data['Company Name']==name].copy().reset_index()\n",
    "    dupe_rows.sort_values(by='last_updated', ascending=False, inplace=True)\n",
    "    rows_to_drop = dupe_rows.iloc[1:, :]\n",
    "    data.drop(index=rows_to_drop['last_updated'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Brabners from the clean file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(?i)\\b\\w*brabners\\w*\\b'\n",
    "data = data[~((data['Company Name'].str.contains(pattern, regex=True)) & (data['Company Name'] != 'NaN'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['First Name', 'Last Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the data to a csv called 'true_north_may_2024_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(WDIR, 'true-north/true_north_clean.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "true-north-n9oHZhgB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
